{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### In the Data Science/Machine Learning world, we often have to read papers to keep up with the state-of-the-art; going through many long papers, however, can be an exhaustive task sometimes. Here, we'll use LangChain to help us as an AI tutor that can receive a list of multiple machine learning papers and answer specific questions that we have on the matter."
      ],
      "metadata": {
        "id": "VMO8pdn0XEHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll use **FAISS** (which is a very fast approximate nearest neighbor algorithm from META) with **OpenAI Embeddings**. Then, given some query representing a specific question we have, FAISS will take the **nearest semantic sentences** by comparing the query embedding with the stored sentence embeddings."
      ],
      "metadata": {
        "id": "mZv9KiQVeLir"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Wn8g88JCpu"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install requests transformers faiss-cpu\n",
        "!pip install PyPDF2\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "56d08n5RJTE9"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "from google.colab import drive\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import pickle\n",
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDoiAEP_u7rE",
        "outputId": "b0fba887-34f5-4c0a-e23c-da453d6f94f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=<OpenAI API key here>\n"
          ]
        }
      ],
      "source": [
        "%env OPENAI_API_KEY = <OpenAI API key here>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtcEDfHQOg2J",
        "outputId": "72389231-1a92-4f6d-c56c-d974de1cf8e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "gdrive_path = '/content/drive/MyDrive/Papers/' # or whatever your Google Folder path is"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(gdrive_path) # some ml papers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z50St0WfGhL",
        "outputId": "e0c337ba-bd8f-4881-8cf6-2a462ab0955b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Representation Learning.pdf', 'GAN.pdf', 'WGAN.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WgvWik96Gi8R"
      },
      "outputs": [],
      "source": [
        "def get_pdf_data(file_path, num_pages = 1):\n",
        "  reader = PdfReader(gdrive_path+file_path)\n",
        "  full_doc_text = \"\"\n",
        "  for page in range(len(reader.pages)):\n",
        "    current_page = reader.pages[page]\n",
        "    text = current_page.extract_text()\n",
        "    full_doc_text += text\n",
        "\n",
        "\n",
        "  return Document(\n",
        "        page_content=full_doc_text,\n",
        "        metadata = {\"source\": file_path}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x5o7bn2J1Vrn"
      },
      "outputs": [],
      "source": [
        "def source_docs():\n",
        "    return [get_pdf_data(file) for file in os.listdir(gdrive_path)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UOG8Dtht8APG"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "def search_index(source_docs):\n",
        "    source_chunks = []\n",
        "    splitter = CharacterTextSplitter(separator=\" \", chunk_size=1024, chunk_overlap=0)\n",
        "\n",
        "    for source in source_docs:\n",
        "        for chunk in splitter.split_text(source.page_content):\n",
        "            source_chunks.append(Document(page_content=chunk, metadata=source.metadata))\n",
        "\n",
        "    vectorindex_openai = FAISS.from_documents(source_chunks, OpenAIEmbeddings())\n",
        "    vectorindex_openai.save_local(\"semantic_chunks/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sources = source_docs()\n",
        "search_index(sources)"
      ],
      "metadata": {
        "id": "hOn5HliNPheK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "x6d-fA3v8Nnf"
      },
      "outputs": [],
      "source": [
        "stuff_chain = load_qa_with_sources_chain(OpenAI(temperature=0),verbose=False, chain_type=\"stuff\")\n",
        "mp_reduce_chain = load_qa_with_sources_chain(OpenAI(temperature=0),verbose=False,chain_type=\"map_reduce\")\n",
        "def print_answer(question, chain):\n",
        "\n",
        "    search_index = FAISS.load_local(\"semantic_chunks\", OpenAIEmbeddings())\n",
        "\n",
        "    try:\n",
        "      print(\n",
        "          chain(\n",
        "              {\n",
        "                  \"input_documents\": search_index.similarity_search(question, k=3),\n",
        "                  \"question\": question,\n",
        "              },\n",
        "              return_only_outputs=True,\n",
        "          )[\"output_text\"]\n",
        "\n",
        "      )\n",
        "    except Exception as e:\n",
        "      print(f\"Unexpected error: {e}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "g2tTFCZ9Wivd"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "sources = source_docs()\n",
        "search_index(sources)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_answer(\"How does the Wasserstein distance improve traditional GANs?\", stuff_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbVnqzsBc6oy",
        "outputId": "a3ba9131-ff85-4574-fbd8-78037a2a19f2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Wasserstein distance improves traditional GANs by providing a meaningful loss metric and improved stability of the optimization process.\n",
            "SOURCES: WGAN.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Responses are good, but now let's compare to when we use map-reduce chains."
      ],
      "metadata": {
        "id": "0npHZkbLcZbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_answer(\"How does the Wasserstein distance improve traditional GANs?\", mp_reduce_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRV-RSFlWnyP",
        "outputId": "ed3b8136-8247-4a87-c520-d634b368d771"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Wasserstein distance allows for cleaner gradients and leverages the geometry of the underlying space, leading to improved evaluation of generative models. \n",
            "SOURCES: WGAN.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Since map-reduce applies the LLM chain to each document separately, instead of gathering all in a single shot (as stuff chain does), the answers have better detail. Using map-reduced chains, however, is also more expensive."
      ],
      "metadata": {
        "id": "_phVyxcKdMF_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsTCmBMrVimn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}